# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_TOPIC=webtoon_user_events_v2

# Schema Registry (avro)
AVSC_PATH=/opt/workspace/src/kafka/schemas/webtoon_user_events_v1.avsc

# Spark
HADOOP_USER_NAME=spark
SPARK_APP_FILE_IN_CONTAINER=/opt/workspace/src/spark/streaming_sessions.py
SPARK_MASTER=spark://spark-master:7077
SPARK_PACKAGES=org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.spark:spark-avro_2.12:3.5.1,org.apache.hadoop:hadoop-aws:3.3.6,com.amazonaws:aws-java-sdk-bundle:1.12.262
SPARK_CHECKPOINT_DIR=file:///opt/workspace/checkpoints
SPARK_PARQUET_INPUT_PATH=s3a://w-userflow-featurestore/input/
SPARK_PARQUET_OUTPUT_PATH=s3a://w-userflow-featurestore/output/

# AWS S3
AMZ_ACC_KEY_ID=AKIAR6ZRGC3ZOV5T4PEM
AMZ_SECRET_ACC_KEY=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

# PostgreSQL
POSTGRES_JDBC_URL=jdbc:postgresql://postgres:5432/airflow
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5432
# POSTGRES_DB=wuserflow
# POSTGRES_USER=byeolong2
# POSTGRES_PASSWORD=adminadmin12
# POSTGRES_TABLE=w_userflow_featurestore

# dbt
# DBT_TARGET=dev
# DBT_PROFILES_DIR=./dbt

# # Great Expectations
# GX_DATA_CONTEXT_ROOT=./gx

# Airflow
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://byeolong2:adminadmin12@postgres/airflow
AIRFLOW__CORE__FERNET_KEY=e0HnUGRP0sdHHyap49MjkPtfx014wS-lSB0OZC3Mfls=
AIRFLOW__WEBSERVER__SECRET_KEY=9TMSmdY7cglmC9k4pzUBya3UQQWhYGBTv6eUCPHIpD0
